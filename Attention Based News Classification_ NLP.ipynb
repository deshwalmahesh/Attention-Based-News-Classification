{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport nltk \nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom string import punctuation\n\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\n\nfrom keras.layers import Dense, Input, LSTM, Bidirectional,Dropout, Embedding, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau\nfrom keras.initializers import Constant\nfrom keras.layers.merge import add\nfrom keras.optimizers import Adam\n\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom keras.utils import np_utils\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"/kaggle/input/bbc-fulltext-and-category/bbc-text.csv\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.50d.txt\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.200d.txt\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 13\n\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords')\n\nsigns = list(punctuation)\n\nstop_words = list(stopwords.words('english'))\n\nwordnet_lemmatizer = WordNetLemmatizer()","execution_count":2,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","name":"stdout"}]},{"metadata":{"_uuid":"9bf30c58fb63b9e0aad9e36b3384ce5e91c83aef"},"cell_type":"markdown","source":"# Proprecess Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/bbc-fulltext-and-category/bbc-text.csv')\ndf.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"        category                                               text\n0           tech  tv future in the hands of viewers with home th...\n1       business  worldcom boss  left books alone  former worldc...\n2          sport  tigers wary of farrell  gamble  leicester say ...\n3          sport  yeading face newcastle in fa cup premiership s...\n4  entertainment  ocean s twelve raids box office ocean s twelve...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tech</td>\n      <td>tv future in the hands of viewers with home th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>business</td>\n      <td>worldcom boss  left books alone  former worldc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sport</td>\n      <td>tigers wary of farrell  gamble  leicester say ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sport</td>\n      <td>yeading face newcastle in fa cup premiership s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>entertainment</td>\n      <td>ocean s twelve raids box office ocean s twelve...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['category'].value_counts().plot(kind='pie',autopct='%.2f%%') # almost equally distributed","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f0739c2ba20>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x7f0739c35198>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYkAAADuCAYAAADMW/vrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBeyaHWkAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_articles(df):\n\n    # remove all the new lines and spaces if there are any : - \\r and \\n\n    print('Step 1: Replacing...')\n    \n    df['text'] = df['text'].str.replace(\"\\r\", \" \")\n    df['text'] = df['text'].str.replace(\"\\n\", \" \")\n    df['text'] = df['text'].str.replace(\"    \", \" \")\n    df['text'] = df['text'].str.replace('\"', '') # remove double quotes\n    df['text'] = df['text'].str.lower()  # make all the words as lower case\n    \n    for sign in signs:\n        df['text'] = df['text'].str.replace(sign, '') # remove any special punctuations\n        \n    # remove Deshwal's the trailing s as it does not add any information in classification\n    df['text'] = df['text'].str.replace(\"'s\", \"\")\n\n\n    print('Step 2: Lemmatizing......')\n    \n    nrows = len(df)\n    lemmatized_text_list = []\n\n    for row in range(nrows):\n        lemmatized_list = [] # Create an empty list containing lemmatized words\n        text = df.loc[row]['text'] # Save the text and its words into an object\n        text_words = text.split(\" \")\n\n        for word in text_words:  # Iterate through every word to lemmatize\n            lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n\n        lemmatized_text = \" \".join(lemmatized_list)  # Join the list to get a string\n        lemmatized_text_list.append(lemmatized_text) # Append to the list containing the texts\n\n    df['text'] = lemmatized_text_list\n    \n    \n    print('Step 3: Removing Stop Words....')\n    \n    for stop_word in stop_words:\n        re_sw = r\"\\b\" + stop_word + r\"\\b\"\n        df['text'] = df['text'].str.replace(re_sw, '')\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_articles(df)","execution_count":5,"outputs":[{"output_type":"stream","text":"Step 1: Replacing...\nStep 2: Lemmatizing......\nStep 3: Removing Stop Words....\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"a5737eceacbb85f26e2cb640332a60881818b100"},"cell_type":"code","source":"def tokenize_articles(df):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(df.text)\n    df['words'] = tokenizer.texts_to_sequences(df.text)\n    \n    return tokenizer","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = tokenize_articles(df)\n\ndf['article_length'] = df.words.apply(lambda i: len(i)) # if article length is less than 10, drop it\ndf = df[df['article_length']>=10]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51f586fa92aff7a859d606622788b11fc51fb197","scrolled":true},"cell_type":"code","source":"df.article_length.describe()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"count    2225.000000\nmean      222.154607\nstd       126.370837\nmin        48.000000\n25%       145.000000\n50%       195.000000\n75%       273.000000\nmax      2212.000000\nName: article_length, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"ea5417ae1057812e360c413f83a44f029c57df8e"},"cell_type":"code","source":"maxlen = 275 # 75 percentile is 273\nX = list(sequence.pad_sequences(df.words, maxlen=maxlen))\n\ndf['encoded_cat'] = LabelEncoder().fit_transform(df['category'])","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"9b133fdfe331a1551e98440f479f9a02349ceb64"},"cell_type":"markdown","source":"# Glove embedding"},{"metadata":{"trusted":true,"_uuid":"af4c3b7b877179ba628315d4dc1fe72bf9db8b1d"},"cell_type":"code","source":"word_index = tokenizer.word_index\n\nEMBEDDING_DIM = 100\n\nembeddings_index = {}\nwith open('/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n\nprint(f'Unique tokens: {len(word_index)}')\nprint(f'Total Word Vectors: {len(embeddings_index)}')","execution_count":10,"outputs":[{"output_type":"stream","text":"Unique tokens: 27859\nTotal Word Vectors: 400000\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"8f23e667f067ac480412511082f758f12bf4caf7"},"cell_type":"code","source":"embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"3216d87143804d30f2d2e51983c3310f46402dc3"},"cell_type":"markdown","source":"# Split Data"},{"metadata":{"trusted":true,"_uuid":"714f2d758c18a70dee1ba7c2d2ac4122da12c45b"},"cell_type":"code","source":"X = np.array(X)\nY = np_utils.to_categorical(df['encoded_cat'].tolist())\n\nx_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=seed)","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"6e148c03fd8c688fc4de4cbf23c9e764b3823a92"},"cell_type":"markdown","source":"# Attention Layer"},{"metadata":{"trusted":true,"_uuid":"d78cf159bb9befb7ab27b5be5954e9ec85fc997d"},"cell_type":"code","source":"class Attention(Layer):\n    '''\n    Implement Attention is all you need's Bhadanau's style Attention\n    '''\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n        if self.bias:\n            eij += self.b\n        eij = K.tanh(eij)\n        a = K.exp(eij)\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Custom Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_layer = Embedding(len(word_index)+1,EMBEDDING_DIM,\n                            embeddings_initializer=Constant(embedding_matrix),input_length=maxlen,\n                            trainable=False) # do not train as these are GloVe pre trained","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = Input(shape=(maxlen,), dtype='int32')\nembedding= embedding_layer(inp)\nattention_out = Attention(maxlen)(embedding)\nflat = Dense(512, activation='relu')(attention_out)\nflat = Dropout(0.63)(flat)\nflat = BatchNormalization()(flat)\nout = Dense(5,activation='softmax')(flat)\n\nAttentionModel = Model(inputs=inp, outputs=out)\nAttentionModel.compile(loss='categorical_crossentropy', optimizer='adam', \n                       metrics=['acc',recall_m,precision_m,f1_m])\n\nAttentionModel.summary()","execution_count":16,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 275)               0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 275, 100)          2786000   \n_________________________________________________________________\nattention_1 (Attention)      (None, 100)               375       \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               51712     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 2565      \n=================================================================\nTotal params: 2,842,700\nTrainable params: 55,676\nNon-trainable params: 2,787,024\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mcp = ModelCheckpoint(filepath='/kaggle/working/best_weights.h5',verbose=1,save_best_only=True,\n                      save_weights_only=True)\nes = EarlyStopping(min_delta=0.003,patience=2,verbose=1)\nrlp = ReduceLROnPlateau(factor=0.003,patience=1,verbose=1,min_delta=0.001,min_lr=1e-6)\n\ncallbacks = [mcp,es,rlp]","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c137a522a0113b183672fdd99939a2dd61d1f38"},"cell_type":"code","source":"training_history = AttentionModel.fit(x_train,y_train,batch_size=32,epochs=10,\n                                      validation_data=(x_val, y_val),callbacks=callbacks)","execution_count":18,"outputs":[{"output_type":"stream","text":"Train on 1780 samples, validate on 445 samples\nEpoch 1/10\n1780/1780 [==============================] - 2s 1ms/step - loss: 0.5368 - acc: 0.8163 - recall_m: 0.7483 - precision_m: 0.8768 - f1_m: 0.7983 - val_loss: 0.1690 - val_acc: 0.9551 - val_recall_m: 0.9461 - val_precision_m: 0.9635 - val_f1_m: 0.9545\n\nEpoch 00001: val_loss improved from inf to 0.16896, saving model to /kaggle/working/best_weights.h5\nEpoch 2/10\n1780/1780 [==============================] - 1s 548us/step - loss: 0.2295 - acc: 0.9360 - recall_m: 0.9107 - precision_m: 0.9490 - f1_m: 0.9292 - val_loss: 0.1386 - val_acc: 0.9573 - val_recall_m: 0.9573 - val_precision_m: 0.9661 - val_f1_m: 0.9616\n\nEpoch 00002: val_loss improved from 0.16896 to 0.13858, saving model to /kaggle/working/best_weights.h5\nEpoch 3/10\n1780/1780 [==============================] - 1s 506us/step - loss: 0.2005 - acc: 0.9421 - recall_m: 0.9270 - precision_m: 0.9550 - f1_m: 0.9406 - val_loss: 0.1062 - val_acc: 0.9640 - val_recall_m: 0.9640 - val_precision_m: 0.9685 - val_f1_m: 0.9663\n\nEpoch 00003: val_loss improved from 0.13858 to 0.10616, saving model to /kaggle/working/best_weights.h5\nEpoch 4/10\n1780/1780 [==============================] - 1s 507us/step - loss: 0.1583 - acc: 0.9528 - recall_m: 0.9416 - precision_m: 0.9611 - f1_m: 0.9510 - val_loss: 0.0969 - val_acc: 0.9685 - val_recall_m: 0.9663 - val_precision_m: 0.9685 - val_f1_m: 0.9674\n\nEpoch 00004: val_loss improved from 0.10616 to 0.09686, saving model to /kaggle/working/best_weights.h5\nEpoch 5/10\n1780/1780 [==============================] - 1s 509us/step - loss: 0.1349 - acc: 0.9539 - recall_m: 0.9455 - precision_m: 0.9607 - f1_m: 0.9529 - val_loss: 0.0818 - val_acc: 0.9753 - val_recall_m: 0.9730 - val_precision_m: 0.9798 - val_f1_m: 0.9763\n\nEpoch 00005: val_loss improved from 0.09686 to 0.08181, saving model to /kaggle/working/best_weights.h5\nEpoch 6/10\n1780/1780 [==============================] - 1s 513us/step - loss: 0.1321 - acc: 0.9551 - recall_m: 0.9466 - precision_m: 0.9584 - f1_m: 0.9524 - val_loss: 0.0791 - val_acc: 0.9753 - val_recall_m: 0.9753 - val_precision_m: 0.9775 - val_f1_m: 0.9764\n\nEpoch 00006: val_loss improved from 0.08181 to 0.07912, saving model to /kaggle/working/best_weights.h5\nEpoch 7/10\n1780/1780 [==============================] - 1s 513us/step - loss: 0.1120 - acc: 0.9624 - recall_m: 0.9579 - precision_m: 0.9665 - f1_m: 0.9621 - val_loss: 0.0745 - val_acc: 0.9753 - val_recall_m: 0.9753 - val_precision_m: 0.9753 - val_f1_m: 0.9753\n\nEpoch 00007: val_loss improved from 0.07912 to 0.07449, saving model to /kaggle/working/best_weights.h5\nEpoch 8/10\n1780/1780 [==============================] - 1s 657us/step - loss: 0.1008 - acc: 0.9669 - recall_m: 0.9629 - precision_m: 0.9737 - f1_m: 0.9682 - val_loss: 0.0669 - val_acc: 0.9775 - val_recall_m: 0.9730 - val_precision_m: 0.9775 - val_f1_m: 0.9752\n\nEpoch 00008: val_loss improved from 0.07449 to 0.06692, saving model to /kaggle/working/best_weights.h5\nEpoch 9/10\n1780/1780 [==============================] - 1s 507us/step - loss: 0.1028 - acc: 0.9657 - recall_m: 0.9618 - precision_m: 0.9705 - f1_m: 0.9661 - val_loss: 0.0664 - val_acc: 0.9775 - val_recall_m: 0.9753 - val_precision_m: 0.9775 - val_f1_m: 0.9764\n\nEpoch 00009: val_loss improved from 0.06692 to 0.06638, saving model to /kaggle/working/best_weights.h5\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-06.\nEpoch 10/10\n1780/1780 [==============================] - 1s 504us/step - loss: 0.0860 - acc: 0.9713 - recall_m: 0.9674 - precision_m: 0.9750 - f1_m: 0.9711 - val_loss: 0.0655 - val_acc: 0.9798 - val_recall_m: 0.9775 - val_precision_m: 0.9820 - val_f1_m: 0.9797\n\nEpoch 00010: val_loss improved from 0.06638 to 0.06553, saving model to /kaggle/working/best_weights.h5\nEpoch 00010: early stopping\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Improvements\nTraining the model took less than a minute using Attention Model and has given us `validation accuracy = 0.9798` without overfitting. We can improve the accuracy by adding either BiDirectional LSTM or GRU cell before AttentionLayer but computation to metric ration won't improve much. \n\nFor the best results, we can use HuggingFace Library's pre-trained SOTA models."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}